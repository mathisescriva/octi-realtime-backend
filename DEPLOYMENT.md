# üöÄ Guide de D√©ploiement - OCTI Realtime Backend

## Vue d'ensemble

Ce backend peut √™tre d√©ploy√© sur n'importe quelle plateforme supportant Node.js. Il expose :
- **WebSocket** : `/ws/realtime` pour conversation directe
- **HTTP API** : `/api/session` pour sessions √©ph√©m√®res (WebRTC)
- **Health Check** : `/health` pour monitoring

## üìã Pr√©requis

- Node.js ‚â• 20
- Cl√© API OpenAI avec acc√®s √† l'API Realtime
- Variables d'environnement configur√©es

## üåê D√©ploiement sur Render

### 1. Cr√©er un nouveau Web Service

1. Aller sur [Render Dashboard](https://dashboard.render.com)
2. Cliquer sur "New +" ‚Üí "Web Service"
3. Connecter votre repository GitHub

### 2. Configuration

**Build Command :**
```bash
npm install && npm run build
```

**Start Command :**
```bash
npm start
```

**Environment Variables :**
```
OPENAI_API_KEY=sk-xxx
OCTI_SYSTEM_PROMPT="Tu es OCTI..."
OCTI_DEFAULT_VOICE=alloy
OPENAI_REALTIME_MODEL=gpt-realtime
PORT=8080
NODE_ENV=production
```

### 3. D√©ployer

Render d√©ploiera automatiquement. Votre backend sera accessible sur :
```
https://your-service.onrender.com
```

## üöÇ D√©ploiement sur Railway

1. Cr√©er un nouveau projet sur [Railway](https://railway.app)
2. Connecter votre repository
3. Ajouter les variables d'environnement
4. Railway d√©tectera automatiquement Node.js et utilisera `npm start`

## üê≥ D√©ploiement avec Docker (optionnel)

Cr√©er un `Dockerfile` :

```dockerfile
FROM node:20-alpine

WORKDIR /app

COPY package*.json ./
RUN npm ci --only=production

COPY . .
RUN npm run build

EXPOSE 8080

CMD ["npm", "start"]
```

Puis :
```bash
docker build -t octi-backend .
docker run -p 8080:8080 --env-file .env octi-backend
```

## üîó Int√©gration avec votre Frontend

### Option 1 : WebSocket Direct

Votre frontend se connecte au WebSocket de votre backend d√©ploy√© :

```javascript
const ws = new WebSocket('wss://your-backend.onrender.com/ws/realtime');
```

### Option 2 : Sessions √âph√©m√®res (WebRTC)

Votre frontend utilise l'endpoint `/api/session` :

```javascript
const response = await fetch('https://your-backend.onrender.com/api/session');
const { client_secret } = await response.json();
// Utiliser client_secret.value pour se connecter √† OpenAI via WebRTC
```

## üîí S√©curit√© en Production

1. **HTTPS/WSS obligatoire** : Utilisez toujours HTTPS en production
2. **CORS** : Configurez CORS pour votre domaine frontend si n√©cessaire
3. **Rate Limiting** : Ajoutez du rate limiting si n√©cessaire
4. **Monitoring** : Surveillez les logs et m√©triques

## üìä Monitoring

### Health Check

```bash
curl https://your-backend.onrender.com/health
```

### Logs

Sur Render/Railway, les logs sont disponibles dans le dashboard.

## üêõ D√©pannage

### Erreur "Incorrect API key provided"

- V√©rifier que `OPENAI_API_KEY` est bien configur√©e
- V√©rifier qu'elle a acc√®s √† l'API Realtime

### Erreur de connexion WebSocket

- V√©rifier que le backend est accessible
- V√©rifier que le port est correctement expos√©
- V√©rifier les logs du serveur

### Pas de r√©ponse audio

- V√©rifier les logs backend
- V√©rifier que l'audio est envoy√© au bon format (PCM16, 24kHz)
- V√©rifier que la session OpenAI est bien cr√©√©e
