import WebSocket from 'ws';
import { logger } from '../../config/logger';
import { SessionManager } from '../../core/sessions/SessionManager';
import { getOctiAgentConfig } from '../../core/agents/octiAgent';
import { OpenAIRealtimeClient } from '../../core/realtime/OpenAIRealtimeClient';
import {
  isFrontendMessage,
  createReadyMessage,
  createBotAudioEndMessage,
  createTranscriptDeltaMessage,
  createErrorMessage,
} from '../../utils/wsMessages';
import {
  ResponseOutputAudioDeltaEvent,
  ResponseOutputAudioTranscriptDeltaEvent,
  ErrorEvent,
} from '../../core/realtime/types';

/**
 * G√®re une connexion WebSocket client pour le service Realtime
 * Fait le proxy entre le frontend et OpenAI Realtime API
 */
export function realtimeHandler(ws: WebSocket): void {
  let realtimeClient: OpenAIRealtimeClient | null = null;

  logger.info('Nouvelle connexion WebSocket client');

  /**
   * Initialise la session Realtime
   */
  async function initializeSession() {
    try {
      const agentConfig = getOctiAgentConfig();
      realtimeClient = await SessionManager.createOctiSession(agentConfig);

      // Configurer les handlers pour les √©v√©nements OpenAI
      realtimeClient.onMessage((event) => {
        handleOpenAIEvent(event);
      });

      // Envoyer ready au frontend
      ws.send(JSON.stringify(createReadyMessage()));
      logger.info('Session Realtime initialis√©e, pr√™t pour le frontend');
    } catch (error) {
      logger.error({ error }, 'Erreur lors de l\'initialisation de la session');
      sendError('Erreur lors de l\'initialisation de la session Realtime');
    }
  }

  /**
   * G√®re les √©v√©nements re√ßus depuis OpenAI Realtime
   */
  function handleOpenAIEvent(event: any) {
    try {
      // Logger TOUS les √©v√©nements pour d√©boguer
      logger.info({ type: event.type, event: JSON.stringify(event).substring(0, 500) }, '√âv√©nement OpenAI re√ßu');
      
      switch (event.type) {
        case 'session.created':
        case 'session.updated':
          logger.info('‚úÖ Session confirm√©e par OpenAI');
          break;
          
        case 'input_audio_buffer.speech_started':
          logger.info('üé§ OpenAI a d√©tect√© le d√©but de la parole');
          break;
          
        case 'input_audio_buffer.speech_stopped':
          logger.info('üîá OpenAI a d√©tect√© la fin de la parole');
          break;
          
        case 'input_audio_buffer.committed':
          logger.info('‚úÖ OpenAI a commit√© l\'audio');
          break;
          
        case 'response.output_audio_transcript.delta': {
          const deltaEvent = event as ResponseOutputAudioTranscriptDeltaEvent;
          logger.info({ delta: deltaEvent.delta.substring(0, 50) }, 'üìù Transcription delta re√ßue');
          ws.send(JSON.stringify(createTranscriptDeltaMessage(deltaEvent.delta)));
          break;
        }

        case 'response.output_audio.delta': {
          const audioEvent = event as ResponseOutputAudioDeltaEvent;
          logger.info({ deltaLength: audioEvent.delta.length }, 'üîä Audio delta re√ßu depuis OpenAI');
          // D√©coder le base64 et envoyer l'audio PCM16 au frontend
          const audioBuffer = Buffer.from(audioEvent.delta, 'base64');
          logger.info({ bufferSize: audioBuffer.length }, 'üì§ Audio d√©cod√© et envoy√© au frontend');
          ws.send(audioBuffer);
          break;
        }

        case 'response.output_audio.done': {
          logger.info('‚úÖ Fin de l\'audio de r√©ponse OpenAI');
          ws.send(JSON.stringify(createBotAudioEndMessage()));
          break;
        }

        case 'response.done': {
          logger.info('‚úÖ R√©ponse compl√®te termin√©e');
          break;
        }

        case 'error': {
          const errorEvent = event as ErrorEvent;
          logger.error({ error: errorEvent.error, fullEvent: JSON.stringify(event) }, '‚ùå Erreur depuis OpenAI Realtime');
          sendError(`Erreur OpenAI: ${errorEvent.error.message}`);
          break;
        }

        default:
          // Logger tous les autres √©v√©nements
          logger.debug({ type: event.type, event: JSON.stringify(event).substring(0, 200) }, '√âv√©nement OpenAI');
          break;
      }
    } catch (error) {
      logger.error({ error, eventType: event.type }, 'Erreur lors du traitement d\'un √©v√©nement OpenAI');
    }
  }

  /**
   * Envoie un message d'erreur au frontend
   */
  function sendError(message: string) {
    try {
      ws.send(JSON.stringify(createErrorMessage(message)));
    } catch (error) {
      logger.error({ error }, 'Impossible d\'envoyer le message d\'erreur');
    }
  }

  /**
   * R√©initialise la session Realtime
   */
  async function resetSession() {
    logger.info('R√©initialisation de la session');
    
    if (realtimeClient) {
      realtimeClient.close();
      realtimeClient = null;
    }

    await initializeSession();
  }

  // Initialiser la session d√®s la connexion
  initializeSession();

  // G√©rer les messages du frontend
  ws.on('message', async (data: WebSocket.Data) => {
    try {
      // Message binaire = chunk audio PCM16 depuis le frontend
      // On doit le convertir en Base64 et l'envoyer via input_audio_buffer.append
      if (Buffer.isBuffer(data) || data instanceof ArrayBuffer) {
        if (!realtimeClient) {
          logger.warn('Tentative d\'envoi d\'audio sans client Realtime');
          return;
        }
        
        if (!realtimeClient.connected) {
          logger.warn('Tentative d\'envoi d\'audio, session non connect√©e. √âtat:', realtimeClient.ws?.readyState);
          // R√©essayer de cr√©er la session si elle est ferm√©e
          if (realtimeClient.ws?.readyState === WebSocket.CLOSED) {
            logger.info('Session ferm√©e, r√©initialisation...');
            await resetSession();
          }
          return;
        }

        // Convertir le buffer PCM16 en Base64 selon la doc
        const buffer = Buffer.isBuffer(data) ? data : Buffer.from(data);
        
        // V√©rifier que le buffer est valide (au moins 100 bytes)
        if (buffer.length < 100) {
          logger.debug({ size: buffer.length }, 'Buffer audio trop petit, ignor√©');
          return;
        }
        
        // Encoder en Base64 et envoyer via input_audio_buffer.append
        const audioBase64 = buffer.toString('base64');
        realtimeClient.sendAudioChunk(audioBase64);
        logger.debug({ size: buffer.length, base64Length: audioBase64.length }, 'Chunk audio envoy√© √† OpenAI via input_audio_buffer.append');
        return;
      }

      // Message JSON
      if (typeof data === 'string') {
        const message = JSON.parse(data);

        if (!isFrontendMessage(message)) {
          logger.warn({ message }, 'Message frontend invalide');
          sendError('Format de message invalide');
          return;
        }

        switch (message.type) {
          case 'start_conversation':
            logger.info('D√©marrage de conversation demand√©');
            break;

          case 'user_audio_end':
            // Avec VAD activ√© (semantic_vad), on n'a PAS besoin d'envoyer input_audio_buffer.commit
            // Le serveur d√©tecte automatiquement la fin de parole et g√©n√®re une r√©ponse
            // On garde ce code pour le cas o√π VAD serait d√©sactiv√©
            logger.info('Fin de l\'audio utilisateur d√©tect√©e (VAD g√®re automatiquement le commit)');
            // Note: Avec VAD activ√©, le commit est automatique, donc on ne fait rien ici
            // Si VAD √©tait d√©sactiv√©, on enverrait:
            // const commitMessage: InputAudioBufferCommitMessage = { type: 'input_audio_buffer.commit' };
            // realtimeClient.sendEvent(commitMessage);
            break;

          case 'reset_session':
            logger.info('Reset de session demand√©');
            await resetSession();
            break;
        }
      }
    } catch (error) {
      logger.error({ error }, 'Erreur lors du traitement d\'un message frontend');
      sendError('Erreur lors du traitement du message');
    }
  });

  // G√©rer la fermeture de la connexion
  ws.on('close', () => {
    logger.info('Connexion WebSocket client ferm√©e');
    if (realtimeClient) {
      realtimeClient.close();
      realtimeClient = null;
    }
  });

  // G√©rer les erreurs de connexion
  ws.on('error', (error) => {
    logger.error({ error }, 'Erreur WebSocket client');
    if (realtimeClient) {
      realtimeClient.close();
      realtimeClient = null;
    }
  });
}
