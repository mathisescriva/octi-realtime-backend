# ðŸ”Œ API Endpoints - OKTI Backend

Documentation des endpoints pour connecter votre frontend.

## âš ï¸ Important : Deux approches possibles

Il existe **deux faÃ§ons** de connecter un frontend Ã  OKTI :

### 1. **Approche SDK OpenAI (recommandÃ©e - utilisÃ©e par le frontend actuel)**

Utilise `/api/session` pour obtenir une clÃ© Ã©phÃ©mÃ¨re, puis se connecte **directement** Ã  OpenAI via WebRTC en utilisant le SDK `@openai/agents/realtime`.

**Avantages :**
- âœ… Toutes les fonctionnalitÃ©s disponibles (texte, interruption, PTT, etc.)
- âœ… Connexion directe Ã  OpenAI (meilleure latence)
- âœ… Gestion complÃ¨te des Ã©vÃ©nements par le SDK

**Voir :** `GUIDE_FRONTEND.md` pour l'implÃ©mentation complÃ¨te.

### 2. **Approche WebSocket Backend**

Utilise `/ws/realtime` pour passer par le backend qui fait le proxy vers OpenAI.

**Avantages :**
- âœ… Plus simple Ã  implÃ©menter (pas besoin du SDK)
- âœ… Le backend gÃ¨re la connexion OpenAI

**Limitations actuelles :**
- âŒ Pas d'envoi de texte (audio uniquement)
- âŒ Pas d'interruption de l'agent
- âŒ Pas de gestion Push-to-Talk (clear/commit buffer)
- âŒ Pas de transcription de l'utilisateur en temps rÃ©el

**Cette documentation couvre l'approche WebSocket Backend.**

---

## Base URL

```
http://localhost:8080  (dÃ©veloppement)
https://your-backend.com  (production)
```

---

## ðŸ“¡ Endpoints HTTP

### GET /health

VÃ©rifie que le serveur est opÃ©rationnel.

**RÃ©ponse :**
```json
{
  "status": "ok",
  "timestamp": "2024-01-01T12:00:00.000Z",
  "service": "octi-realtime-backend"
}
```

**Exemple :**
```javascript
const response = await fetch('http://localhost:8080/health');
const data = await response.json();
console.log(data.status); // "ok"
```

---

### GET /api/session

CrÃ©e une session Ã©phÃ©mÃ¨re OpenAI Realtime. Retourne un `client_secret` pour connexion directe Ã  OpenAI via WebRTC.

**âš ï¸ UtilisÃ© par l'approche SDK OpenAI (voir `GUIDE_FRONTEND.md`)**

**RÃ©ponse :**
```json
{
  "object": "realtime.session",
  "id": "sess_xxx",
  "model": "gpt-realtime-2025-08-28",
  "client_secret": {
    "value": "ek_xxx",
    "expires_at": 1234567890
  },
  "instructions": "...",
  "voice": "verse",
  ...
}
```

**Exemple :**
```javascript
const response = await fetch('http://localhost:8080/api/session');
const session = await response.json();
const ephemeralKey = session.client_secret.value;
// Utiliser ephemeralKey avec le SDK OpenAI Agents pour se connecter directement
```

**Note :** Pour utiliser cette approche, voir `GUIDE_FRONTEND.md` qui documente l'utilisation complÃ¨te du SDK.

---

### POST /api/rag/search

Recherche dans les documents ESCE via RAG (utilisÃ© par l'agent OKTI).

**Body :**
```json
{
  "query": "votre question"
}
```

**RÃ©ponse :**
```json
{
  "context": "contexte trouvÃ© dans les documents...",
  "length": 1234
}
```

**Note :** Cet endpoint est principalement utilisÃ© par l'agent OKTI via ses outils. Vous pouvez l'utiliser directement pour tester le RAG.

---

## ðŸ”Œ WebSocket Endpoint

### WS /ws/realtime

Endpoint WebSocket pour conversation directe avec OKTI via le backend.

**âš ï¸ Limitations :** Cette approche ne supporte actuellement que l'audio. Pour toutes les fonctionnalitÃ©s (texte, interruption, PTT), utilisez l'approche SDK avec `/api/session`.

**URL :**
```
ws://localhost:8080/ws/realtime  (dÃ©veloppement)
wss://your-backend.com/ws/realtime  (production)
```

**FonctionnalitÃ©s supportÃ©es :**
- âœ… Envoi d'audio (PCM16, 24kHz, mono)
- âœ… RÃ©ception d'audio
- âœ… Transcription de l'agent en temps rÃ©el
- âœ… Reset de session

**FonctionnalitÃ©s non supportÃ©es (Ã  venir) :**
- âŒ Envoi de texte
- âŒ Interruption de l'agent
- âŒ Push-to-Talk (clear/commit buffer)
- âŒ Transcription de l'utilisateur en temps rÃ©el

---

## ðŸ“¤ Messages Frontend â†’ Backend

### 1. DÃ©marrer la conversation

```json
{ "type": "start_conversation" }
```

**Quand l'envoyer :** Au dÃ©but de la conversation, aprÃ¨s avoir reÃ§u `ready`.

---

### 2. Envoyer un chunk audio

**Format :** Binaire (ArrayBuffer), PCM16, 24kHz, mono

```javascript
// Votre audio doit Ãªtre en PCM16, 24kHz, mono
const pcm16Buffer = convertToPCM16(audioData); // Int16Array
ws.send(pcm16Buffer.buffer); // Envoyer l'ArrayBuffer
```

**Important :**
- Format : PCM16 (16-bit signed integers)
- Sample rate : 24000 Hz
- Channels : Mono (1 canal)
- Le backend convertit automatiquement en Base64 et l'envoie Ã  OpenAI

---

### 3. Fin de la parole utilisateur (optionnel)

```json
{ "type": "user_audio_end" }
```

**Note :** Avec `semantic_vad` activÃ©, ce message n'est gÃ©nÃ©ralement pas nÃ©cessaire car OpenAI dÃ©tecte automatiquement la fin de parole.

---

### 4. Reset session

```json
{ "type": "reset_session" }
```

RÃ©initialise la session et en crÃ©e une nouvelle.

---

## ðŸ“¥ Messages Backend â†’ Frontend

### 1. Backend prÃªt

```json
{ "type": "ready" }
```

**Quand reÃ§u :** Automatiquement aprÃ¨s la connexion WebSocket, quand la session OpenAI est initialisÃ©e et confirmÃ©e.

**Action :** Vous pouvez maintenant envoyer `start_conversation` et commencer Ã  envoyer de l'audio.

---

### 2. Chunk audio du bot

**Format :** Binaire (ArrayBuffer), PCM16, 24kHz, mono

```javascript
ws.onmessage = (event) => {
  if (event.data instanceof ArrayBuffer) {
    // C'est de l'audio PCM16, 24kHz, mono
    const audioBuffer = event.data;
    playAudio(audioBuffer);
  }
};
```

**Important :**
- Format : PCM16 (16-bit signed integers)
- Sample rate : 24000 Hz
- Channels : Mono (1 canal)
- Ã€ jouer directement dans votre AudioContext

---

### 3. Fin de la rÃ©ponse vocale

```json
{ "type": "bot_audio_end" }
```

**Quand reÃ§u :** Quand le bot a fini de parler.

**Action :** Vous pouvez indiquer Ã  l'utilisateur qu'il peut parler Ã  nouveau.

---

### 4. Transcription texte (optionnel)

```json
{ "type": "transcript_delta", "text": "..." }
```

**Quand reÃ§u :** Pendant que le bot parle, pour afficher la transcription en temps rÃ©el.

**Exemple :**
```javascript
if (message.type === 'transcript_delta') {
  transcriptElement.textContent += message.text;
}
```

---

### 5. Erreur

```json
{ "type": "error", "message": "..." }
```

**Quand reÃ§u :** En cas d'erreur (connexion OpenAI, session, etc.)

**Action :** Afficher l'erreur Ã  l'utilisateur.

---

## ðŸ’» Exemple Complet Frontend

```javascript
// 1. Connexion WebSocket
const ws = new WebSocket('ws://localhost:8080/ws/realtime');

let isReady = false;

ws.onopen = () => {
  console.log('âœ… ConnectÃ© au backend');
};

ws.onmessage = async (event) => {
  // Message JSON
  if (typeof event.data === 'string') {
    const message = JSON.parse(event.data);
    
    switch (message.type) {
      case 'ready':
        isReady = true;
        console.log('âœ… Backend prÃªt');
        // DÃ©marrer la conversation
        ws.send(JSON.stringify({ type: 'start_conversation' }));
        break;
        
      case 'bot_audio_end':
        console.log('ðŸ”š Bot a fini de parler');
        break;
        
      case 'transcript_delta':
        console.log('ðŸ“ Transcription:', message.text);
        updateTranscript(message.text);
        break;
        
      case 'error':
        console.error('âŒ Erreur:', message.message);
        break;
    }
  } 
  // Audio binaire
  else if (event.data instanceof ArrayBuffer) {
    console.log('ðŸ”Š Audio reÃ§u:', event.data.byteLength, 'bytes');
    await playAudio(event.data);
  }
};

ws.onerror = (error) => {
  console.error('âŒ Erreur WebSocket:', error);
};

ws.onclose = () => {
  console.log('ðŸ”Œ Connexion fermÃ©e');
  isReady = false;
};

// 2. Envoyer de l'audio (PCM16, 24kHz, mono)
function sendAudio(audioData) {
  if (!isReady || ws.readyState !== WebSocket.OPEN) {
    return;
  }
  
  // Convertir en PCM16 si nÃ©cessaire
  const pcm16 = convertToPCM16(audioData); // Int16Array
  ws.send(pcm16.buffer); // Envoyer l'ArrayBuffer
}

// 3. Jouer l'audio reÃ§u
async function playAudio(audioBuffer) {
  const audioContext = new AudioContext({ sampleRate: 24000 });
  const pcm16 = new Int16Array(audioBuffer);
  const float32 = new Float32Array(pcm16.length);
  
  // Convertir PCM16 vers Float32
  for (let i = 0; i < pcm16.length; i++) {
    float32[i] = pcm16[i] / 32768.0;
  }
  
  const buffer = audioContext.createBuffer(1, float32.length, 24000);
  buffer.getChannelData(0).set(float32);
  
  const source = audioContext.createBufferSource();
  source.buffer = buffer;
  source.connect(audioContext.destination);
  source.start();
}
```

---

## ðŸ“‹ SpÃ©cifications Audio

### Format d'entrÃ©e (Frontend â†’ Backend)
- **Format :** PCM16 (16-bit signed integers)
- **Sample rate :** 24000 Hz
- **Channels :** Mono (1 canal)
- **Encoding :** Little-endian

### Format de sortie (Backend â†’ Frontend)
- **Format :** PCM16 (16-bit signed integers)
- **Sample rate :** 24000 Hz
- **Channels :** Mono (1 canal)
- **Encoding :** Little-endian

---

## ðŸ”— URLs de Connexion

### DÃ©veloppement
- WebSocket : `ws://localhost:8080/ws/realtime`
- HTTP : `http://localhost:8080`

### Production
- WebSocket : `wss://your-backend.com/ws/realtime`
- HTTP : `https://your-backend.com`

**Important :** Utilisez `wss://` (WebSocket Secure) en production avec HTTPS.

---

## ðŸ“Š Comparaison des approches

| FonctionnalitÃ© | SDK OpenAI (`/api/session`) | WebSocket Backend (`/ws/realtime`) |
|----------------|----------------------------|-----------------------------------|
| Audio (parler) | âœ… | âœ… |
| Audio (Ã©couter) | âœ… | âœ… |
| Envoi de texte | âœ… | âŒ |
| Interruption | âœ… | âŒ |
| Push-to-Talk | âœ… | âŒ |
| Transcription utilisateur | âœ… | âŒ |
| Transcription agent | âœ… | âœ… |
| RAG (outils) | âœ… | âœ… |
| Latence | Faible (direct) | Moyenne (via backend) |
| ComplexitÃ© | Moyenne (SDK requis) | Faible (WebSocket simple) |

**Recommandation :** Utilisez l'approche SDK (`/api/session`) pour un frontend complet avec toutes les fonctionnalitÃ©s. Utilisez l'approche WebSocket Backend (`/ws/realtime`) uniquement si vous avez besoin d'une solution simple sans le SDK.

---

## ðŸ”— Ressources

- **Guide Frontend complet** : `GUIDE_FRONTEND.md` (approche SDK)
- **Documentation OpenAI Realtime** : https://platform.openai.com/docs/guides/realtime
- **SDK OpenAI Agents** : https://github.com/openai/agents

