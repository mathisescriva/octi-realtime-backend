# ðŸ”Œ API Endpoints - OKTI Backend

Documentation des endpoints pour connecter votre frontend.

## Base URL

```
http://localhost:8080  (dÃ©veloppement)
https://your-backend.com  (production)
```

---

## ðŸ“¡ Endpoints HTTP

### GET /health

VÃ©rifie que le serveur est opÃ©rationnel.

**RÃ©ponse :**
```json
{
  "status": "ok",
  "timestamp": "2024-01-01T12:00:00.000Z",
  "service": "octi-realtime-backend"
}
```

**Exemple :**
```javascript
const response = await fetch('http://localhost:8080/health');
const data = await response.json();
console.log(data.status); // "ok"
```

---

### GET /api/session

CrÃ©e une session Ã©phÃ©mÃ¨re OpenAI Realtime. Retourne un `client_secret` pour connexion directe Ã  OpenAI via WebRTC.

**RÃ©ponse :**
```json
{
  "object": "realtime.session",
  "id": "sess_xxx",
  "model": "gpt-realtime",
  "client_secret": {
    "value": "ek_xxx",
    "expires_at": 1234567890
  },
  "instructions": "...",
  "voice": "alloy",
  ...
}
```

**Exemple :**
```javascript
const response = await fetch('http://localhost:8080/api/session');
const session = await response.json();
const ephemeralKey = session.client_secret.value;
// Utiliser ephemeralKey pour se connecter Ã  OpenAI via WebRTC
```

---

## ðŸ”Œ WebSocket Endpoint

### WS /ws/realtime

Endpoint WebSocket pour conversation directe avec OKTI.

**URL :**
```
ws://localhost:8080/ws/realtime  (dÃ©veloppement)
wss://your-backend.com/ws/realtime  (production)
```

---

## ðŸ“¤ Messages Frontend â†’ Backend

### 1. DÃ©marrer la conversation

```json
{ "type": "start_conversation" }
```

**Quand l'envoyer :** Au dÃ©but de la conversation, aprÃ¨s avoir reÃ§u `ready`.

---

### 2. Envoyer un chunk audio

**Format :** Binaire (ArrayBuffer), PCM16, 24kHz, mono

```javascript
// Votre audio doit Ãªtre en PCM16, 24kHz, mono
const pcm16Buffer = convertToPCM16(audioData); // Int16Array
ws.send(pcm16Buffer.buffer); // Envoyer l'ArrayBuffer
```

**Important :**
- Format : PCM16 (16-bit signed integers)
- Sample rate : 24000 Hz
- Channels : Mono (1 canal)
- Le backend convertit automatiquement en Base64 et l'envoie Ã  OpenAI

---

### 3. Fin de la parole utilisateur (optionnel)

```json
{ "type": "user_audio_end" }
```

**Note :** Avec `semantic_vad` activÃ©, ce message n'est gÃ©nÃ©ralement pas nÃ©cessaire car OpenAI dÃ©tecte automatiquement la fin de parole.

---

### 4. Reset session

```json
{ "type": "reset_session" }
```

RÃ©initialise la session et en crÃ©e une nouvelle.

---

## ðŸ“¥ Messages Backend â†’ Frontend

### 1. Backend prÃªt

```json
{ "type": "ready" }
```

**Quand reÃ§u :** Automatiquement aprÃ¨s la connexion WebSocket, quand la session OpenAI est initialisÃ©e et confirmÃ©e.

**Action :** Vous pouvez maintenant envoyer `start_conversation` et commencer Ã  envoyer de l'audio.

---

### 2. Chunk audio du bot

**Format :** Binaire (ArrayBuffer), PCM16, 24kHz, mono

```javascript
ws.onmessage = (event) => {
  if (event.data instanceof ArrayBuffer) {
    // C'est de l'audio PCM16, 24kHz, mono
    const audioBuffer = event.data;
    playAudio(audioBuffer);
  }
};
```

**Important :**
- Format : PCM16 (16-bit signed integers)
- Sample rate : 24000 Hz
- Channels : Mono (1 canal)
- Ã€ jouer directement dans votre AudioContext

---

### 3. Fin de la rÃ©ponse vocale

```json
{ "type": "bot_audio_end" }
```

**Quand reÃ§u :** Quand le bot a fini de parler.

**Action :** Vous pouvez indiquer Ã  l'utilisateur qu'il peut parler Ã  nouveau.

---

### 4. Transcription texte (optionnel)

```json
{ "type": "transcript_delta", "text": "..." }
```

**Quand reÃ§u :** Pendant que le bot parle, pour afficher la transcription en temps rÃ©el.

**Exemple :**
```javascript
if (message.type === 'transcript_delta') {
  transcriptElement.textContent += message.text;
}
```

---

### 5. Erreur

```json
{ "type": "error", "message": "..." }
```

**Quand reÃ§u :** En cas d'erreur (connexion OpenAI, session, etc.)

**Action :** Afficher l'erreur Ã  l'utilisateur.

---

## ðŸ’» Exemple Complet Frontend

```javascript
// 1. Connexion WebSocket
const ws = new WebSocket('ws://localhost:8080/ws/realtime');

let isReady = false;

ws.onopen = () => {
  console.log('âœ… ConnectÃ© au backend');
};

ws.onmessage = async (event) => {
  // Message JSON
  if (typeof event.data === 'string') {
    const message = JSON.parse(event.data);
    
    switch (message.type) {
      case 'ready':
        isReady = true;
        console.log('âœ… Backend prÃªt');
        // DÃ©marrer la conversation
        ws.send(JSON.stringify({ type: 'start_conversation' }));
        break;
        
      case 'bot_audio_end':
        console.log('ðŸ”š Bot a fini de parler');
        break;
        
      case 'transcript_delta':
        console.log('ðŸ“ Transcription:', message.text);
        updateTranscript(message.text);
        break;
        
      case 'error':
        console.error('âŒ Erreur:', message.message);
        break;
    }
  } 
  // Audio binaire
  else if (event.data instanceof ArrayBuffer) {
    console.log('ðŸ”Š Audio reÃ§u:', event.data.byteLength, 'bytes');
    await playAudio(event.data);
  }
};

ws.onerror = (error) => {
  console.error('âŒ Erreur WebSocket:', error);
};

ws.onclose = () => {
  console.log('ðŸ”Œ Connexion fermÃ©e');
  isReady = false;
};

// 2. Envoyer de l'audio (PCM16, 24kHz, mono)
function sendAudio(audioData) {
  if (!isReady || ws.readyState !== WebSocket.OPEN) {
    return;
  }
  
  // Convertir en PCM16 si nÃ©cessaire
  const pcm16 = convertToPCM16(audioData); // Int16Array
  ws.send(pcm16.buffer); // Envoyer l'ArrayBuffer
}

// 3. Jouer l'audio reÃ§u
async function playAudio(audioBuffer) {
  const audioContext = new AudioContext({ sampleRate: 24000 });
  const pcm16 = new Int16Array(audioBuffer);
  const float32 = new Float32Array(pcm16.length);
  
  // Convertir PCM16 vers Float32
  for (let i = 0; i < pcm16.length; i++) {
    float32[i] = pcm16[i] / 32768.0;
  }
  
  const buffer = audioContext.createBuffer(1, float32.length, 24000);
  buffer.getChannelData(0).set(float32);
  
  const source = audioContext.createBufferSource();
  source.buffer = buffer;
  source.connect(audioContext.destination);
  source.start();
}
```

---

## ðŸ“‹ SpÃ©cifications Audio

### Format d'entrÃ©e (Frontend â†’ Backend)
- **Format :** PCM16 (16-bit signed integers)
- **Sample rate :** 24000 Hz
- **Channels :** Mono (1 canal)
- **Encoding :** Little-endian

### Format de sortie (Backend â†’ Frontend)
- **Format :** PCM16 (16-bit signed integers)
- **Sample rate :** 24000 Hz
- **Channels :** Mono (1 canal)
- **Encoding :** Little-endian

---

## ðŸ”— URLs de Connexion

### DÃ©veloppement
- WebSocket : `ws://localhost:8080/ws/realtime`
- HTTP : `http://localhost:8080`

### Production
- WebSocket : `wss://your-backend.com/ws/realtime`
- HTTP : `https://your-backend.com`

**Important :** Utilisez `wss://` (WebSocket Secure) en production avec HTTPS.

