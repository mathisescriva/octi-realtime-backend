# ğŸš€ Setup RAG pour OKTI - Guide Simple

## ğŸ“‹ PrÃ©requis

1. **Compte Pinecone** (gratuit) : https://www.pinecone.io/
2. **Documents Ã  ingÃ©rer** : PDFs et Excel dans le dossier `documents/`

---

## ğŸ”§ Ã‰tape 1 : Setup Pinecone

1. CrÃ©er un compte sur https://www.pinecone.io/ (gratuit)
2. CrÃ©er un index :
   - Nom : `esce-documents` (ou autre)
   - Dimensions : `1536` (pour text-embedding-3-small)
   - Metric : `cosine`
3. RÃ©cupÃ©rer votre API Key

---

## ğŸ”§ Ã‰tape 2 : Configuration

Ajouter dans votre `.env` :

```env
PINECONE_API_KEY=votre-clÃ©-api-pinecone
PINECONE_INDEX_NAME=esce-documents
```

---

## ğŸ”§ Ã‰tape 3 : Installer les dÃ©pendances

```bash
npm install
```

---

## ğŸ”§ Ã‰tape 4 : Organiser vos documents

Placez vos documents dans :

```
documents/
  â”œâ”€â”€ brochures/
  â”‚   â”œâ”€â”€ brochure-esce-2024.pdf
  â”‚   â””â”€â”€ ...
  â”œâ”€â”€ guides/
  â”‚   â”œâ”€â”€ guide-etudiant.pdf
  â”‚   â””â”€â”€ ...
  â”œâ”€â”€ stages/
  â”‚   â”œâ”€â”€ historiques-stages.xlsx
  â”‚   â””â”€â”€ ...
  â””â”€â”€ linkedin/
      â”œâ”€â”€ profil-etudiant-1.pdf
      â””â”€â”€ ...
```

---

## ğŸ”§ Ã‰tape 5 : IngÃ©rer les documents

```bash
npm run ingest
```

Le script va :
1. Parser tous les PDFs et Excel
2. CrÃ©er des chunks de texte
3. GÃ©nÃ©rer des embeddings (OpenAI)
4. Stocker dans Pinecone

**Temps estimÃ© :** 2-5 minutes selon le nombre de documents

---

## âœ… C'est tout !

Le backend va maintenant :
- âœ… Utiliser automatiquement le tool RAG si Pinecone est configurÃ©
- âœ… Rechercher dans les documents quand un Ã©tudiant pose une question
- âœ… Injecter le contexte dans la conversation
- âœ… RÃ©pondre avec les informations des documents

---

## ğŸš€ DÃ©ploiement sur Render

1. Ajouter les variables d'environnement dans Render :
   - `PINECONE_API_KEY`
   - `PINECONE_INDEX_NAME` (optionnel, par dÃ©faut `esce-documents`)

2. **Important :** L'ingestion se fait **en local**, pas sur Render
   - ExÃ©cutez `npm run ingest` en local
   - Les documents sont stockÃ©s dans Pinecone (cloud)
   - Le backend sur Render utilise juste l'API Pinecone

---

## ğŸ” Comment Ã§a marche ?

1. **Ã‰tudiant pose une question** : "Quels sont les prÃ©requis pour International Business?"
2. **OKTI dÃ©tecte** qu'il a besoin d'informations
3. **Tool RAG appelÃ©** : Recherche dans Pinecone
4. **Contexte trouvÃ©** : Extrait des brochures/guides
5. **OKTI rÃ©pond** : Avec les informations prÃ©cises des documents

---

## ğŸ› DÃ©pannage

### "PINECONE_API_KEY non dÃ©finie"
â†’ VÃ©rifiez votre `.env` et redÃ©marrez le serveur

### "Index not found"
â†’ VÃ©rifiez que l'index existe dans Pinecone avec le bon nom

### "Aucun rÃ©sultat trouvÃ©"
â†’ VÃ©rifiez que l'ingestion s'est bien passÃ©e (`npm run ingest`)

---

## ğŸ“Š Latence

- **Avec cache** : < 1ms (requÃªtes frÃ©quentes)
- **Sans cache** : 50-100ms (recherche Pinecone + embedding)
- **Acceptable** : Oui, la latence est nÃ©gligeable pour une conversation vocale


