<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OCTI - Voice Agent</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }
        .container {
            background: white;
            padding: 40px;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
            max-width: 800px;
            width: 100%;
            text-align: center;
        }
        h1 {
            color: #333;
            margin-bottom: 10px;
            font-size: 32px;
        }
        .subtitle {
            color: #666;
            margin-bottom: 30px;
            font-size: 14px;
        }
        .status {
            padding: 15px;
            margin: 20px 0;
            border-radius: 10px;
            font-weight: 600;
            font-size: 16px;
            transition: all 0.3s;
        }
        .status.idle {
            background: #e9ecef;
            color: #495057;
        }
        .status.listening {
            background: #d4edda;
            color: #155724;
            animation: pulse 1.5s infinite;
        }
        .status.speaking {
            background: #fff3cd;
            color: #856404;
            animation: pulse 1.5s infinite;
        }
        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.7; }
        }
        .button {
            padding: 15px 30px;
            margin: 5px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border: none;
            border-radius: 50px;
            cursor: pointer;
            font-size: 16px;
            font-weight: 600;
            transition: all 0.3s;
            box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);
        }
        .button:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(102, 126, 234, 0.6);
        }
        .button:disabled {
            background: #ccc;
            cursor: not-allowed;
            box-shadow: none;
        }
        .button.active {
            background: linear-gradient(135deg, #dc3545 0%, #c82333 100%);
            box-shadow: 0 4px 15px rgba(220, 53, 69, 0.4);
        }
        .button.secondary {
            background: linear-gradient(135deg, #ffc107 0%, #ff9800 100%);
        }
        .transcript {
            background: #f8f9fa;
            border: 2px solid #e9ecef;
            border-radius: 10px;
            padding: 20px;
            margin: 20px 0;
            min-height: 150px;
            max-height: 300px;
            overflow-y: auto;
            text-align: left;
            font-size: 16px;
            line-height: 1.6;
        }
        .transcript .user {
            color: #667eea;
            margin-bottom: 10px;
        }
        .transcript .bot {
            color: #764ba2;
            margin-bottom: 10px;
        }
        .transcript .status-text {
            color: #999;
            font-style: italic;
            text-align: center;
            padding: 20px;
        }
        .mic-indicator {
            width: 80px;
            height: 80px;
            border-radius: 50%;
            margin: 20px auto;
            background: #e9ecef;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 40px;
            transition: all 0.3s;
        }
        .mic-indicator.active {
            background: #dc3545;
            animation: pulse 1s infinite;
        }
        .mic-indicator.listening {
            background: #28a745;
        }
        .info {
            margin-top: 20px;
            padding: 15px;
            background: #e7f3ff;
            border-radius: 10px;
            color: #004085;
            font-size: 14px;
        }
        .error {
            background: #f8d7da;
            color: #721c24;
            padding: 15px;
            border-radius: 10px;
            margin: 20px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üéôÔ∏è OCTI</h1>
        <p class="subtitle">Assistant vocal intelligent - Conversation en temps r√©el</p>
        
        <div id="status" class="status idle">
            ‚ö†Ô∏è D√©connect√©
        </div>
        
        <div class="mic-indicator" id="micIndicator">üé§</div>
        
        <button id="toggleBtn" class="button" onclick="toggleConversation()">
            D√©marrer la conversation
        </button>
        
        <div class="transcript" id="transcript">
            <div class="status-text">Connectez-vous pour commencer...</div>
        </div>
        
        <div class="info" id="info">
            Cliquez sur "D√©marrer la conversation" pour commencer
        </div>
        
        <div id="error" class="error" style="display: none;"></div>
    </div>

    <script>
        let ws = null;
        let audioContext = null;
        let mediaStream = null;
        let processor = null;
        let isConversationActive = false;
        let isListening = false;
        let isBotSpeaking = false;
        let silenceTimer = null;
        let vadThreshold = 0.005; // Seuil plus bas pour d√©tecter plus facilement
        let silenceDuration = 1500;
        let audioProcessCount = 0;
        let animationFrameId = null;
        
        const statusEl = document.getElementById('status');
        const toggleBtn = document.getElementById('toggleBtn');
        const transcriptEl = document.getElementById('transcript');
        const micIndicatorEl = document.getElementById('micIndicator');
        const infoEl = document.getElementById('info');
        const errorEl = document.getElementById('error');

        function showError(message) {
            errorEl.textContent = message;
            errorEl.style.display = 'block';
            setTimeout(() => {
                errorEl.style.display = 'none';
            }, 5000);
        }

        function updateStatus(type, text) {
            statusEl.className = `status ${type}`;
            statusEl.textContent = text;
        }

        function updateTranscript(speaker, text, append = false) {
            if (!append) {
                transcriptEl.innerHTML = '';
            }
            
            const entry = document.createElement('div');
            entry.className = speaker;
            entry.textContent = speaker === 'user' ? `üë§ Vous: ${text}` : `ü§ñ OCTI: ${text}`;
            transcriptEl.appendChild(entry);
            transcriptEl.scrollTop = transcriptEl.scrollHeight;
        }

        function connect() {
            const wsUrl = 'ws://localhost:8080/ws/realtime';
            console.log('üîå Tentative de connexion √†:', wsUrl);
            infoEl.textContent = 'Connexion au backend...';
            
            ws = new WebSocket(wsUrl);

            ws.onopen = () => {
                console.log('‚úÖ WebSocket connect√©');
                updateStatus('connected', '‚úÖ Connect√©');
                infoEl.textContent = 'Connect√© ! Cliquez sur "D√©marrer la conversation"';
                toggleBtn.disabled = false;
            };

            ws.onmessage = async (event) => {
                console.log('üì® Message re√ßu, type:', typeof event.data, 'size:', event.data.byteLength || event.data.length);
                if (typeof event.data === 'string') {
                    const message = JSON.parse(event.data);
                    console.log('üì® Message JSON:', message);
                    handleMessage(message);
                } else {
                    console.log('üîä Audio re√ßu:', event.data.byteLength, 'bytes');
                    await playAudio(event.data);
                }
            };

            ws.onerror = (error) => {
                console.error('‚ùå WebSocket error:', error);
                showError('Erreur de connexion WebSocket. V√©rifiez que le serveur est d√©marr√©.');
                updateStatus('idle', '‚ùå Erreur de connexion');
            };

            ws.onclose = (event) => {
                console.log('üîå WebSocket ferm√©, code:', event.code, 'reason:', event.reason);
                updateStatus('idle', '‚ö†Ô∏è D√©connect√©');
                toggleBtn.disabled = true;
                infoEl.textContent = 'D√©connect√©. Reconnexion...';
                setTimeout(connect, 2000);
            };
        }

        function handleMessage(message) {
            switch (message.type) {
                case 'ready':
                    if (!isConversationActive) {
                        infoEl.textContent = 'Pr√™t ! Cliquez sur "D√©marrer la conversation"';
                    }
                    break;
                case 'transcript_delta':
                    updateTranscript('bot', message.text, true);
                    break;
                case 'bot_audio_end':
                    isBotSpeaking = false;
                    if (isConversationActive) {
                        updateStatus('listening', 'üé§ √âcoute... Parlez maintenant');
                        micIndicatorEl.className = 'mic-indicator listening';
                    }
                    break;
                case 'error':
                    showError(`Erreur: ${message.message}`);
                    console.error('Error:', message.message);
                    break;
            }
        }

        let audioQueue = [];
        let isPlayingAudio = false;
        
        async function playAudio(audioData) {
            if (!isConversationActive) {
                console.log('‚ö†Ô∏è Audio ignor√©, conversation inactive');
                return;
            }
            
            console.log('üîä Audio ajout√© √† la queue:', audioData.byteLength, 'bytes');
            // Ajouter √† la queue
            audioQueue.push(audioData);
            
            if (!isPlayingAudio) {
                isPlayingAudio = true;
                console.log('‚ñ∂Ô∏è D√©marrage de la lecture audio');
                processAudioQueue();
            }
        }
        
        async function processAudioQueue() {
            if (audioQueue.length === 0) {
                isPlayingAudio = false;
                isBotSpeaking = false;
                if (isConversationActive) {
                    updateStatus('listening', 'üé§ √âcoute... Parlez maintenant');
                    micIndicatorEl.className = 'mic-indicator listening';
                }
                return;
            }
            
            isBotSpeaking = true;
            updateStatus('speaking', 'üîä OCTI parle...');
            micIndicatorEl.className = 'mic-indicator';
            
            const audioData = audioQueue.shift();
            const pcm16 = new Int16Array(audioData);
            const float32 = new Float32Array(pcm16.length);
            for (let i = 0; i < pcm16.length; i++) {
                float32[i] = pcm16[i] / 32768.0;
            }
            
            const playContext = new (window.AudioContext || window.webkitAudioContext)({
                sampleRate: 24000
            });
            
            const audioBuffer = playContext.createBuffer(1, float32.length, 24000);
            audioBuffer.getChannelData(0).set(float32);
            
            const source = playContext.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(playContext.destination);
            source.onended = () => {
                playContext.close();
                // Traiter le prochain chunk
                processAudioQueue();
            };
            source.start();
        }

        async function toggleConversation() {
            if (!isConversationActive) {
                await startConversation();
            } else {
                stopConversation();
            }
        }

        async function startConversation() {
            try {
                console.log('üé§ D√©marrage de la conversation...');
                infoEl.textContent = 'D√©marrage de la conversation...';
                
                if (!ws || ws.readyState !== WebSocket.OPEN) {
                    console.error('‚ùå WebSocket non connect√©');
                    showError('WebSocket non connect√©. Attendez la connexion.');
                    return;
                }
                
                console.log('üì§ Envoi: start_conversation');
                ws.send(JSON.stringify({ type: 'start_conversation' }));
                
                console.log('üé§ Demande d\'acc√®s au micro...');
                mediaStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        channelCount: 1,
                        sampleRate: 24000,
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    }
                });

                audioContext = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: 24000
                });

                const source = audioContext.createMediaStreamSource(mediaStream);
                
                // Utiliser ScriptProcessorNode pour capturer l'audio brut
                // Note: d√©pr√©ci√© mais n√©cessaire pour capturer les donn√©es audio brutes
                // TODO: Migrer vers AudioWorklet pour une solution moderne
                processor = audioContext.createScriptProcessor(4096, 1, 1);

                processor.onaudioprocess = (e) => {
                    if (!isConversationActive || isBotSpeaking) return;
                    
                    const inputData = e.inputBuffer.getChannelData(0);
                    
                    // Calculer le niveau audio pour VAD
                    let sum = 0;
                    for (let i = 0; i < inputData.length; i++) {
                        sum += Math.abs(inputData[i]);
                    }
                    const audioLevel = sum / inputData.length;
                    
                    // Log p√©riodique pour d√©boguer
                    audioProcessCount++;
                    if (audioProcessCount % 100 === 0) {
                        console.log('üîä Niveau audio:', audioLevel.toFixed(6), 'Seuil:', vadThreshold);
                    }
                    
                    // D√©tection de voix (VAD)
                    if (audioLevel > vadThreshold) {
                        if (!isListening) {
                            console.log('üé§ Voix d√©tect√©e ! Niveau:', audioLevel.toFixed(4), 'Seuil:', vadThreshold);
                            isListening = true;
                            updateStatus('listening', 'üé§ Vous parlez...');
                            micIndicatorEl.className = 'mic-indicator active';
                        }
                        
                        if (silenceTimer) clearTimeout(silenceTimer);
                        
                        // Convertir en PCM16 et envoyer
                        const pcm16 = new Int16Array(inputData.length);
                        for (let i = 0; i < inputData.length; i++) {
                            const s = Math.max(-1, Math.min(1, inputData[i]));
                            pcm16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                        }
                        
                        if (ws && ws.readyState === WebSocket.OPEN) {
                            ws.send(pcm16.buffer);
                            if (audioProcessCount % 50 === 0) {
                                console.log('üì§ Audio envoy√©:', pcm16.length, 'samples');
                            }
                        } else {
                            console.warn('‚ö†Ô∏è WebSocket non pr√™t pour envoyer audio');
                        }
                        
                        silenceTimer = setTimeout(() => {
                            if (isListening && !isBotSpeaking) {
                                endUserSpeech();
                            }
                        }, silenceDuration);
                    } else {
                        if (isListening && !isBotSpeaking) {
                            if (!silenceTimer) {
                                silenceTimer = setTimeout(() => {
                                    endUserSpeech();
                                }, silenceDuration);
                            }
                        }
                    }
                };

                // Connecter source -> processor (sans destination pour √©viter l'audio en double)
                source.connect(processor);
                // NE PAS connecter processor √† destination pour √©viter l'audio en double

                isConversationActive = true;
                toggleBtn.textContent = 'Arr√™ter la conversation';
                toggleBtn.classList.add('active');
                updateStatus('listening', 'üé§ √âcoute... Parlez maintenant');
                micIndicatorEl.className = 'mic-indicator listening';
                infoEl.textContent = 'Parlez naturellement, je d√©tecte automatiquement votre voix';
                transcriptEl.innerHTML = '<div class="status-text">Conversation d√©marr√©e. Parlez maintenant...</div>';
                
                console.log('‚úÖ Conversation d√©marr√©e avec succ√®s');
                console.log('üé§ Micro activ√©, √©coute en cours...');
                console.log('üí° Parlez maintenant - le niveau audio sera affich√© dans la console');
                
            } catch (error) {
                console.error('‚ùå Erreur lors du d√©marrage:', error);
                showError(`Erreur: ${error.message}`);
            }
        }

        function endUserSpeech() {
            if (!isListening || isBotSpeaking) return;
            
            console.log('üîö Fin de la parole d√©tect√©e, envoi de user_audio_end');
            isListening = false;
            updateStatus('speaking', 'ü§ñ OCTI r√©fl√©chit et r√©pond...');
            micIndicatorEl.className = 'mic-indicator';
            
            if (ws && ws.readyState === WebSocket.OPEN) {
                ws.send(JSON.stringify({ type: 'user_audio_end' }));
                console.log('üì§ user_audio_end envoy√©');
            } else {
                console.error('‚ùå WebSocket non pr√™t pour envoyer user_audio_end');
            }
            
            if (silenceTimer) {
                clearTimeout(silenceTimer);
                silenceTimer = null;
            }
        }

        function stopConversation() {
            isConversationActive = false;
            isListening = false;
            isBotSpeaking = false;
            
            if (silenceTimer) {
                clearTimeout(silenceTimer);
                silenceTimer = null;
            }
            
            if (animationFrameId) {
                cancelAnimationFrame(animationFrameId);
                animationFrameId = null;
            }
            
            if (processor) {
                processor.disconnect();
                processor = null;
            }
            
            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }
            
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
            }
            
            toggleBtn.textContent = 'D√©marrer la conversation';
            toggleBtn.classList.remove('active');
            updateStatus('connected', '‚úÖ Connect√© (conversation arr√™t√©e)');
            micIndicatorEl.className = 'mic-indicator';
            infoEl.textContent = 'Conversation arr√™t√©e. Cliquez pour red√©marrer.';
        }

        // Connexion automatique au chargement
        window.addEventListener('load', () => {
            connect();
        });
    </script>
</body>
</html>
